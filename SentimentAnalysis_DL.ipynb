{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "lmnF8syn0lhG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"processed_training.csv\")\n",
        "train_texts = train_data[\"text\"]\n",
        "train_labels = train_data[\"label\"]\n",
        "test_data = pd.read_csv(\"processed_test.csv\")\n",
        "test_texts = test_data[\"text\"]\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "vocab_len = len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "12bwWQNGECe3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countVectorizer = CountVectorizer()\n",
        "tfidfTransformer = TfidfTransformer()\n",
        "training_count_matrix = countVectorizer.fit_transform(train_texts)\n",
        "training_tfidf_matrix = tfidfTransformer.fit_transform(training_count_matrix)"
      ],
      "metadata": {
        "id": "dPF-Gx_GiDzO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sentence_length_train = 61\n",
        "max_sentence_length_test = 28"
      ],
      "metadata": {
        "id": "u8rV69BqoBc-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehotmatrix(texts,max_sen_len):\n",
        "  listoflists = tokenizer.texts_to_sequences(texts)\n",
        "  for list in listoflists:\n",
        "    list.extend([0]*(max_sen_len-len(list)))\n",
        "  return np.array([np.array(e) for e in train_onehot])\n",
        "\n",
        "train_onehot = onehotmatrix(train_texts,61)\n",
        "test_onehot = onehotmatrix(test_texts,61)"
      ],
      "metadata": {
        "id": "zNLXPOHVvr5V"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Embedding(input_dim=vocab_len+1,output_dim=64,mask_zero=True),\n",
        "                          keras.layers.GlobalAveragePooling1D(),\n",
        "                          keras.layers.Dense(units=16,activation='relu'),\n",
        "                          keras.layers.Dense(units=6,activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "LQHAZX9QE-A7"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=sparse_categorical_crossentropy,metrics=['acc'])"
      ],
      "metadata": {
        "id": "o1c6IBXJC_YP"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDvm39efDU-s",
        "outputId": "88172a46-a80d-45a2-cccc-a4c65bd2e1b3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 64)          897344    \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 898,486\n",
            "Trainable params: 898,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_onehot[1000:], train_labels[1000:], validation_data=(train_onehot[:1000],train_labels[:1000]), epochs = 10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_aLWHpcDxtz",
        "outputId": "f7308164-bcb0-43a2-aa55-17fec3ba9cb9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "532/532 [==============================] - 8s 13ms/step - loss: 1.3129 - acc: 0.5132 - val_loss: 0.8342 - val_acc: 0.7200\n",
            "Epoch 2/10\n",
            "532/532 [==============================] - 7s 12ms/step - loss: 0.5117 - acc: 0.8463 - val_loss: 0.5098 - val_acc: 0.8280\n",
            "Epoch 3/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.2446 - acc: 0.9355 - val_loss: 0.4439 - val_acc: 0.8450\n",
            "Epoch 4/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.1462 - acc: 0.9628 - val_loss: 0.4682 - val_acc: 0.8430\n",
            "Epoch 5/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0995 - acc: 0.9745 - val_loss: 0.5067 - val_acc: 0.8360\n",
            "Epoch 6/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0731 - acc: 0.9811 - val_loss: 0.5694 - val_acc: 0.8240\n",
            "Epoch 7/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0559 - acc: 0.9861 - val_loss: 0.6108 - val_acc: 0.8210\n",
            "Epoch 8/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0448 - acc: 0.9886 - val_loss: 0.6586 - val_acc: 0.8250\n",
            "Epoch 9/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0364 - acc: 0.9901 - val_loss: 0.7260 - val_acc: 0.8150\n",
            "Epoch 10/10\n",
            "532/532 [==============================] - 7s 13ms/step - loss: 0.0312 - acc: 0.9921 - val_loss: 0.7917 - val_acc: 0.8160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f471b0d2610>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_prob = model.predict(test_onehot)\n",
        "prediction_labels = []\n",
        "for row in prediction_prob:\n",
        "  prediction_labels.append(list(row).index(max(row)))\n",
        "prediction_labels\n",
        "submission = pd.DataFrame(list(zip(list(range(1,2001)), prediction_labels)),columns =['id', 'label']).to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "SE-Yz_6GGEsq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UM2HdGdW7Zyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}